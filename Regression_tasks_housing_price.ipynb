{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> ML Project\n",
    "\n",
    "Project Description:\n",
    "- Preprocess data: Explore data and apply data scaling.\n",
    "\n",
    "Regression Task:\n",
    "- Apply any two models with bagging and any two models with pasting.\n",
    "- Apply any two models with adaboost boosting\n",
    "- Apply one model with gradient boosting\n",
    "- Apply PCA on data and then apply all the models in project 1 again on data you get from PCA. Compare your results with results in project 2. You don't need to apply all the models twice. Just copy the result table from project 1, prepare similar table for all the models after PCA and compare both tables. Does PCA help in getting better results?\n",
    "- Apply deep learning models covered in class\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the csv file from Project 1 which was created by exporting the dataset with one-hot encoding perfomed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_sales = pd.read_csv(\"house_sales_1h.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_sales = house_sales.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_sales.head(10)\n",
    "house_sales.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house_sales.drop(['price'],axis=1)\n",
    "y = house_sales['price']\n",
    "\n",
    "X_train_org, X_test_org, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "y_train.shape\n",
    "y_test.shape\n",
    "X_train_org.shape\n",
    "X_test_org.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scale = scaler.fit_transform(X_train_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scale = scaler.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply any two model with bagging and pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression with bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "lass = Lasso(alpha = 10)\n",
    "bag_clf = BaggingRegressor(lass,n_estimators=500, max_samples=100, bootstrap=True, random_state=0, oob_score=True)\n",
    "bag_clf.fit(X_train_org, y_train)\n",
    "y_pred = bag_clf.predict(X_test_org)\n",
    "bag_clf.score(X_train_org, y_train)\n",
    "bag_clf.score(X_test_org, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  matplotlib.colors  import ListedColormap\n",
    "\n",
    "def plot_decision_boundary(clf, X, y, axes=[-1.5, 2.5, -1, 1.5], alpha=0.5, contour=True):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if contour:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", alpha=alpha)\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", alpha=alpha)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plot_decision_boundary(bag_clf, X, y)\n",
    "plt.title(\"Decision Trees with Bagging\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression with pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "lass = Lasso(alpha = 10)\n",
    "bag_clf = BaggingRegressor(lass,n_estimators=500, max_samples=100, bootstrap=False, random_state=0)\n",
    "bag_clf.fit(X_train_org, y_train)\n",
    "y_pred = bag_clf.predict(X_test_org)\n",
    "bag_clf.score(X_train_org, y_train)\n",
    "bag_clf.score(X_test_org, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "plt.subplot(121)\n",
    "plot_decision_boundary(tree_clf, X, y)\n",
    "plt.title(\"Decision Tree\", fontsize=14)\n",
    "plt.subplot(122)\n",
    "plot_decision_boundary(bag_clf, X, y)\n",
    "plt.title(\"Decision Trees with Bagging\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN regression with bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors = 10)\n",
    "bag_clf = BaggingRegressor(knn,n_estimators=500, max_samples=100, bootstrap=True, random_state=0, oob_score=True)\n",
    "bag_clf.fit(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train score: {:.2f}'.format(bag_clf.score(X_train_scale, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag_clf.score(X_test_scale, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "plt.subplot(121)\n",
    "plot_decision_boundary(tree_clf, X, y)\n",
    "plt.title(\"Decision Tree\", fontsize=14)\n",
    "plt.subplot(122)\n",
    "plot_decision_boundary(bag_clf, X, y)\n",
    "plt.title(\"Decision Trees with Bagging\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN regression with pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingRegressor(knn,n_estimators=500, max_samples=100, bootstrap=False, random_state=0)\n",
    "bag_clf.fit(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf.score(X_train_scale, y_train)\n",
    "bag_clf.score(X_test_scale, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "plt.subplot(121)\n",
    "plot_decision_boundary(tree_clf, X, y)\n",
    "plt.title(\"Decision Tree\", fontsize=14)\n",
    "plt.subplot(122)\n",
    "plot_decision_boundary(bag_clf, X, y)\n",
    "plt.title(\"Decision Trees with Bagging\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Regression with AdaBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "ada_clf = AdaBoostRegressor(knn,n_estimators=200,learning_rate = 1)\n",
    "ada_clf.fit(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf.score(X_train_scale, y_train)\n",
    "ada_clf.score(X_test_scale, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plot_decision_boundary(ada_clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "m = len(X_train)\n",
    "\n",
    "plt.figure(figsize=(11, 4))\n",
    "for  subplot,  learning_rate  in ((121, 1), (122, 0.5)):\n",
    "    sample_weights = np.ones(m)\n",
    "    plt.subplot(subplot)\n",
    "    for i in range(5):\n",
    "#         svm_clf = SVC(kernel=\"rbf\", C=0.05, random_state=42)\n",
    "        ada_clf.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "        y_pred = ada_clf.predict(X_train)\n",
    "        sample_weights[y_pred != y_train] *= (1 + learning_rate)\n",
    "        plot_decision_boundary(ada_clf, X, y, alpha=0.2)\n",
    "        plt.title(\"learning_rate = {}\".format(learning_rate), fontsize=16)\n",
    "    if subplot == 121:\n",
    "        plt.text(-0.7, -0.65, \"1\", fontsize=14)\n",
    "        plt.text(-0.6, -0.10, \"2\", fontsize=14)\n",
    "        plt.text(-0.5,  0.10, \"3\", fontsize=14)\n",
    "        plt.text(-0.4,  0.55, \"4\", fontsize=14)\n",
    "        plt.text(-0.3,  0.90, \"5\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso regression with Adaboosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostRegressor(lass, n_estimators=200, learning_rate=0.25, random_state=0)\n",
    "ada_clf.fit(X_train_org, y_train)\n",
    "ada_clf.score(X_train_org, y_train)\n",
    "ada_clf.score(X_test_org, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plot_decision_boundary(ada_clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "m = len(X_train)\n",
    "\n",
    "plt.figure(figsize=(11, 4))\n",
    "for  subplot,  learning_rate  in ((121, 1), (122, 0.5)):\n",
    "    sample_weights = np.ones(m)\n",
    "    plt.subplot(subplot)\n",
    "    for i in range(5):\n",
    "#         svm_clf = SVC(kernel=\"rbf\", C=0.05, random_state=42)\n",
    "        ada_clf.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "        y_pred = ada_clf.predict(X_train)\n",
    "        sample_weights[y_pred != y_train] *= (1 + learning_rate)\n",
    "        plot_decision_boundary(ada_clf, X, y, alpha=0.2)\n",
    "        plt.title(\"learning_rate = {}\".format(learning_rate), fontsize=16)\n",
    "    if subplot == 121:\n",
    "        plt.text(-0.7, -0.65, \"1\", fontsize=14)\n",
    "        plt.text(-0.6, -0.10, \"2\", fontsize=14)\n",
    "        plt.text(-0.5,  0.10, \"3\", fontsize=14)\n",
    "        plt.text(-0.4,  0.55, \"4\", fontsize=14)\n",
    "        plt.text(-0.3,  0.90, \"5\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0, random_state=42)\n",
    "gbrt.fit(X_train_org, y_train)\n",
    "gbrt.score(X_train_org, y_train)\n",
    "gbrt.score(X_test_org, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  plot_predictions(regressors, X, y, axes, label=None, style=\"r-\", data_style=\"b.\", data_label=None):\n",
    "    x1 = np.linspace(axes[0], axes[1], 500)\n",
    "    y_pred = sum(regressor.predict(x1.reshape(-1, 1)) for regressor in regressors)\n",
    "    plt.plot(X[:, 0], y, data_style, label=data_label)\n",
    "    plt.plot(x1, y_pred, style, linewidth=2, label=label)\n",
    "    if label or data_label:\n",
    "        plt.legend(loc=\"upper center\", fontsize=16)\n",
    "    plt.axis(axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_predictions([gbrt], X, y, axes=[-0.5, 0.5, -0.1, 0.8], label=\"Ensemble predictions\")\n",
    "plt.title(\"learning_rate={}, n_estimators={}\".format(gbrt.learning_rate, gbrt.n_estimators), fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_predictions([gbrt_slow], X, y, axes=[-0.5, 0.5, -0.1, 0.8])\n",
    "plt.title(\"learning_rate={}, n_estimators={}\".format(gbrt_slow.learning_rate, gbrt_slow.n_estimators), fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_scale)\n",
    "\n",
    "pca.explained_variance_ratio_\n",
    "\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 23)\n",
    "X_train_pca = pca.fit_transform(X_train_scale)\n",
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.fit_transform(X_train_scale)\n",
    "X_test_pca = pca.transform(X_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca.shape\n",
    "X_test_pcas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "model = LinearRegression()\n",
    "parameters = {'normalize':[True,False]}\n",
    "grid_search_lr = GridSearchCV(model,parameters, cv=6, return_train_score=True)\n",
    "grid_search_lr.fit(X_train_pca, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search_lr.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_search_lr.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_search_lr.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = LinearRegression(normalize = True)\n",
    "lreg.fit(X_train_pca, y_train)\n",
    "print(lreg.score(X_train_pca, y_train))\n",
    "lr_test_score = lreg.score(X_test_pca, y_test)\n",
    "lr_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "  \n",
    "kfold = KFold(n_splits=6)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(lreg , X_train_pca, y_train, cv=kfold)))\n",
    "scores = cross_val_score(lreg , X_train_pca, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Result:\n",
    "\n",
    "Best parameter: {'normalize': False}\n",
    "\n",
    "Average Cross validation score: 0.7038\n",
    "\n",
    "Test score: 0.7057"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parms_knn = {'n_neighbors':[1,5,10,15,20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "grid_search_knn = GridSearchCV(knn, grid_parms_knn,cv=6,return_train_score=True,n_jobs= -1)\n",
    "grid_search_knn.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search_knn.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_search_knn.best_score_))\n",
    "pd.DataFrame(grid_search_knn.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors = 10)\n",
    "knn.fit(X_train_pca, y_train)\n",
    "print(knn.score(X_train_pca, y_train))\n",
    "knn_test_score_ = knn.score(X_test_pca, y_test)\n",
    "knn_test_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "  \n",
    "kfold = KFold(n_splits=6)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(knn , X_train_pca, y_train, cv=kfold)))\n",
    "scores = cross_val_score(knn , X_train_pca, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_b = X_train_array[:50,2].reshape(-1,1)\n",
    "y_b = y_train[:50]\n",
    "\n",
    "knn_reg = KNeighborsRegressor(10)\n",
    "knn_reg.fit(X_b, y_b)\n",
    "\n",
    "X_new=np.linspace(X_b.min(), X_b.max(), 50).reshape(50, 1)\n",
    "y_predict = knn_reg.predict(X_new)\n",
    "\n",
    "plt.plot(X_new, y_predict, c = 'r')\n",
    "plt.scatter(X_b, y_b)\n",
    "plt.xlabel('sqft_living')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regression Result:\n",
    "\n",
    "Best parameter: {n_neighbors: 10}\n",
    "\n",
    "Average Cross validation score: 0.7050\n",
    "\n",
    "Test score: 0.7091"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parms_ridge = {'alpha': [0.01, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "grid_search_ridge = GridSearchCV(estimator = ridge,param_grid = grid_parms_ridge,return_train_score=True,n_jobs= -1,cv=5)\n",
    "grid_search_ridge.fit(X_train_pca, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search_ridge.best_params_))\n",
    "\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_search_ridge.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha = 1)\n",
    "ridge.fit(X_train_pca, y_train)\n",
    "print(ridge.score(X_train_pca, y_train))\n",
    "ridge_test_score_ = ridge.score(X_test_pca, y_test)\n",
    "ridge_test_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "  \n",
    "kfold = KFold(n_splits=6)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(ridge , X_train_org, y_train, cv=kfold)))\n",
    "scores = cross_val_score(ridge , X_train_org, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ridge = pd.DataFrame(grid_search_ridge.cv_results_)\n",
    "result_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(result_ridge.shape[0]), result_ridge['mean_train_score'], label = 'mean train score')\n",
    "plt.plot(range(result_ridge.shape[0]), result_ridge['mean_test_score'], label = 'mean test score')\n",
    "plt.xticks(range(result_ridge.shape[0]), result_ridge['param_alpha'], rotation = 90)\n",
    "plt.plot([grid_search_ridge.best_index_], result_ridge['mean_train_score'][grid_search_ridge.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.plot([grid_search_ridge.best_index_], result_ridge['mean_test_score'][grid_search_ridge.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('Alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression Result:\n",
    "\n",
    "Best parameter: {'alpha': 1}\n",
    "\n",
    "Average Cross validation score: 0.7038\n",
    "\n",
    "Test score: 0.7058"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parms_lasso = {'alpha': [0.01, 0.1, 1, 10,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "grid_search_lasso = GridSearchCV(estimator = lasso,param_grid = grid_parms_lasso,return_train_score=True,n_jobs=-1,cv=5)\n",
    "grid_search_lasso.fit(X_train_pca, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search_lasso.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_search_lasso.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lass = Lasso(alpha = 10)\n",
    "lass.fit(X_train_pca, y_train)\n",
    "print(lass.score(X_train_pca, y_train))\n",
    "lass_test_score_ = lass.score(X_test_pca, y_test)\n",
    "lass_test_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "  \n",
    "kfold = KFold(n_splits=6)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(lass , X_train_pca, y_train, cv=kfold)))\n",
    "scores = cross_val_score(lass , X_train_pca, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lasso = pd.DataFrame(grid_search_lasso.cv_results_)\n",
    "result_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(result_lasso.shape[0]), result_lasso['mean_train_score'], label = 'mean train score')\n",
    "plt.plot(range(result_lasso.shape[0]), result_lasso['mean_test_score'], label = 'mean test score')\n",
    "plt.xticks(range(result_lasso.shape[0]), result_lasso['param_alpha'], rotation = 90)\n",
    "plt.plot([grid_search_lasso.best_index_], result_lasso['mean_train_score'][grid_search_lasso.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.plot([grid_search_lasso.best_index_], result_lasso['mean_test_score'][grid_search_lasso.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('Alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression Result:\n",
    "\n",
    "Best parameter: {'alpha': 100}\n",
    "\n",
    "Average Cross validation score: 0.7038\n",
    "\n",
    "Test score: 0.7057"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynominal Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                         LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_poly = {'polynomialfeatures__degree': np.arange(3)}\n",
    "\n",
    "grid_poly = GridSearchCV(PolynomialRegression(), param_grid_poly,return_train_score=True,n_jobs=-1,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_poly.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters: {}\".format(grid_poly.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_poly.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol = PolynomialFeatures(degree = 2)\n",
    "X_pol = pol.fit_transform(X_train_scale)\n",
    "Xt_pol = pol.fit_transform(X_test_scale)\n",
    "pol_reg = LinearRegression()\n",
    "pol_reg.fit(X_pol,y_train)\n",
    "print(pol_reg.score(X_pol, y_train))\n",
    "pol_reg_test_score = pol_reg.score(Xt_pol, y_test)\n",
    "pol_reg_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "  \n",
    "kfold = KFold(n_splits=6)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(pol_reg , X_pol, y_train, cv=kfold)))\n",
    "scores = cross_val_score(pol_reg , X_pol, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_poly = pd.DataFrame(grid_poly.cv_results_)\n",
    "result_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(result_poly.shape[0]), result_poly['mean_train_score'], label = 'mean train score')\n",
    "plt.plot(range(result_poly.shape[0]), result_poly['mean_test_score'], label = 'mean test score')\n",
    "plt.xticks(range(result_poly.shape[0]), result_poly['param_polynomialfeatures__degree'], rotation = 90)\n",
    "plt.plot([grid_poly.best_index_], result_poly['mean_train_score'][grid_poly.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.plot([grid_poly.best_index_], result_poly['mean_test_score'][grid_poly.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.grid()\n",
    "plt.xlabel('Degree')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynominal Regression Result:\n",
    "\n",
    "Best parameters: {'polynomialfeatures__degree': 2}\n",
    "\n",
    "Average Cross validation score: 0.7888\n",
    "\n",
    "Test score: 0.7942"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear (Simple) SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parms_svrl = {'C': [0.01, 0.1, 1, 10, 100], 'epsilon' : [0.01, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearsvr = LinearSVR()\n",
    "grid_svrl = GridSearchCV(estimator = linearsvr,param_grid = grid_parms_svrl,return_train_score=True,n_jobs= -1,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svrl.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters: {}\".format(grid_svrl.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_svrl.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvr = LinearSVR(C = 100, epsilon = 1)\n",
    "        \n",
    "lsvr.fit(X_train_pca, y_train)\n",
    "\n",
    "print(lsvr.score(X_train_pca, y_train))\n",
    "lsvr_test_score = lsvr.score(X_test_pca, y_test)\n",
    "lsvr_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "  \n",
    "kfold = KFold(n_splits=10)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(lsvr , X_train_pca, y_train, cv=kfold)))\n",
    "scores = cross_val_score(lsvr, X_train_pca, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_linearsvr = pd.DataFrame(grid_svrl.cv_results_)\n",
    "result_linearsvr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(result_linearsvr.shape[0]), result_linearsvr['mean_train_score'], label = 'mean train score')\n",
    "plt.plot(range(result_linearsvr.shape[0]), result_linearsvr['mean_test_score'], label = 'mean test score')\n",
    "plt.xticks(range(result_linearsvr.shape[0]), result_linearsvr['param_C'], rotation = 90)\n",
    "plt.plot([grid_svrl.best_index_], result_linearsvr['mean_train_score'][grid_svrl.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.plot([grid_svrl.best_index_], result_linearsvr['mean_test_score'][grid_svrl.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('Alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear (Simple) SVR  Result:\n",
    "\n",
    "Best parameters: {'C': 100, 'epsilon': 1}\n",
    "\n",
    "Average Cross validation score: 0.5548\n",
    "\n",
    "Test score: 0.5714"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR with kernel 'Linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parms_linear = {'C': [0.01,0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_linear = SVR(kernel='linear')\n",
    "grid_svr_linear = GridSearchCV(estimator = svr_linear,param_grid = grid_parms_linear,return_train_score=True,n_jobs= -1,cv=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svr_linear.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters: {}\".format(grid_svr_linear.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_svr_linear.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svr = SVR(kernel = 'linear',C = 100)\n",
    "        \n",
    "        #train the model\n",
    "svr.fit(X_train_pca, y_train)\n",
    "        \n",
    "        #evaluate the model\n",
    "print(svr.score(X_train_pca, y_train))\n",
    "svr_test_score = svr.score(X_test_pca, y_test)\n",
    "svr_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kfold = KFold(n_splits=6)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(svr , X_train_pca, y_train, cv=kfold)))\n",
    "scores = cross_val_score(svr , X_train_pca, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_svr_linear = pd.DataFrame(grid_svr_linear.cv_results_)\n",
    "result_svr_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(result_svr_linear.shape[0]), result_svr_linear['mean_train_score'], label = 'mean train score')\n",
    "plt.plot(range(result_svr_linear.shape[0]), result_svr_linear['mean_test_score'], label = 'mean test score')\n",
    "plt.xticks(range(result_svr_linear.shape[0]), result_svr_linear['param_C'], rotation = 90)\n",
    "plt.plot([grid_svr_linear.best_index_], result_svr_linear['mean_train_score'][grid_svr_linear.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.plot([grid_svr_linear.best_index_], result_svr_linear['mean_test_score'][grid_svr_linear.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR with Kernel as 'Linear' Result:\n",
    "\n",
    "Best parameters: {'C': 100}\n",
    "\n",
    "Average Cross validation score: 0.6313\n",
    "\n",
    "Test score: 0.6353"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR with kernel 'Poly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parms_svrp = {'C': [1, 10, 100],'degree':[1,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_poly = SVR(kernel='poly')\n",
    "grid_svr_poly = GridSearchCV(estimator = svr_poly,param_grid = grid_parms_svrp,return_train_score=True,n_jobs= -1,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svr_poly.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters: {}\".format(grid_svr_poly.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_svr_poly.best_score_))\n",
    "pd.DataFrame(grid_svr_poly.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_p = SVR(kernel='poly',C=100,degree = 1)\n",
    "svr_p.fit(X_train_scale, y_train)\n",
    "svr_p.score(X_train_scale, y_train)\n",
    "svrp_test_score = svr_p.score(X_test_scale, y_test)\n",
    "svrp_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#scores = cross_val_score(logreg, iris.data, iris.target)\n",
    "kfold = KFold(n_splits=6)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(svr_p, X_train_scale, y_train, cv=kfold)))\n",
    "scores = cross_val_score(svr_p, X_train_scale, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_svr_poly= pd.DataFrame(grid_svr_poly.cv_results_)\n",
    "result_svr_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(result_svr_poly.shape[0]), result_svr_poly['mean_train_score'], label = 'mean train score')\n",
    "plt.plot(range(result_svr_poly.shape[0]), result_svr_poly['mean_test_score'], label = 'mean test score')\n",
    "plt.xticks(range(result_svr_poly.shape[0]), result_svr_poly['param_C'], rotation = 90)\n",
    "plt.plot([grid_svr_poly.best_index_], result_svr_poly['mean_train_score'][grid_svr_poly.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.plot([grid_svr_poly.best_index_], result_svr_poly['mean_test_score'][grid_svr_poly.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR with Kernel as 'Poly' Result:\n",
    "\n",
    "Best parameters: {'C': 100, 'degree': 1}\n",
    "\n",
    "Average Cross validation score: 0.2491\n",
    "\n",
    "Test score: 0.2900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR with kernel 'rbf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parms_rbf = {'C': [0.1, 1, 10, 100],'gamma':[0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel='rbf')\n",
    "grid_svr_rbf = GridSearchCV(estimator = svr_rbf,param_grid = grid_parms_rbf,return_train_score=True,n_jobs= -1,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svr_rbf.fit(X_train_scale,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters: {}\".format(grid_svr_rbf.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_svr_rbf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel='rbf',C=100,gamma=0.1)\n",
    "svr_rbf.fit(X_train_scale, y_train)\n",
    "svr_rbf.score(X_train_scale, y_train)\n",
    "svr_rbf_test_score = svr_rbf.score(X_test_scale, y_test)\n",
    "svr_rbf_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "kfold = KFold(n_splits=6)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(svr_rbf, X_train_scale, y_train, cv=kfold)))\n",
    "scores = cross_val_score(svr_rbf, X_train_scale, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rbf = pd.DataFrame(grid_svr_rbf.cv_results_)\n",
    "result_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(result_rbf.shape[0]), result_rbf['mean_train_score'], label = 'mean train score')\n",
    "plt.plot(range(result_rbf.shape[0]), result_rbf['mean_test_score'], label = 'mean test score')\n",
    "plt.xticks(range(result_svr_poly.shape[0]), result_rbf['param_C'], rotation = 90)\n",
    "plt.plot([grid_svr_rbf.best_index_], result_rbf['mean_train_score'][grid_svr_rbf.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.plot([grid_svr_rbf.best_index_], result_rbf['mean_test_score'][grid_svr_rbf.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR with Kernel as 'rbf' Result:\n",
    "\n",
    "Best parameters: {'C': 100, 'gamma': 0.1}\n",
    "\n",
    "Average Cross validation score: -0.0372\n",
    "\n",
    "Test score: -0.0345"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
